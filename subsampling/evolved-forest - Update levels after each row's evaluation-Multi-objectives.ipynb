{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Experiment: Single Objective Variance of True Probablity\n",
    "\n",
    "#### Aim\n",
    "\n",
    "Each row is provided as marks which will be allotted to the **individual** if it solves that row. Each row has marks = **pop_size**.\n",
    "\n",
    "If one individual solves a problem then the marks allotted to that row will decrease so that other inidividuals can focus on other rows for gaining marks. But the marks will not decresase beyond **40% of pop_size**\n",
    "\n",
    "My only concern is that in last when it becomes an ensemble will there be enough votes for the ensemble to predict?\n",
    "\n",
    "#### How does it make sure the accuracy is also increasing?\n",
    "\n",
    "\n",
    "#### Critism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "digits = load_digits()\n",
    "digit_features, digit_labels = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(digit_features, digit_labels, stratify=digit_labels,train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base DecisionTreeClassifier accuracy: 0.851441241685\n",
      "Base RandomForestClassifier accuracy: 0.942350332594\n",
      "Base GradientBoostingClassifier accuracy: 0.955654101996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The exploration of the dataset by benchmark algorithms\n",
    "clf = DecisionTreeClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_DTC = clf.predict(X_test)\n",
    "print('Base DecisionTreeClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf = RandomForestClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_RFC = clf.predict(X_test)\n",
    "print('Base RandomForestClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_GBC = clf.predict(X_test)\n",
    "print('Base GradientBoostingClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_marks = 100\n",
    "min_marks = 0.33*max_marks\n",
    "diff_global_marks = np.ones(y_test.shape[0])\n",
    "diff_global_marks = diff_global_marks*max_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_unseen(population):\n",
    "    forest_predictions = []\n",
    "    for ind_num, individual in enumerate(population):\n",
    "        func = toolbox.compile(expr=individual)\n",
    "        \n",
    "        \n",
    "        sample_counts = [int(func(*record)) for record in X_train]\n",
    "        sample_counts = [max(min(sample_count, 10), 0) for sample_count in sample_counts]\n",
    "        sample = []\n",
    "        for sample_index, sample_count in enumerate(sample_counts):\n",
    "            sample.extend([sample_index] * sample_count)\n",
    "        sample = np.array(sample)\n",
    "\n",
    "        if len(sample) == 0:\n",
    "            return 1e-20, 1e-20\n",
    "\n",
    "        clf = DecisionTreeClassifier(random_state=34092)\n",
    "        clf.fit(X_train[sample], y_train[sample])\n",
    "        predictions = clf.predict(X_test)\n",
    "        forest_predictions.append(predictions)\n",
    "        \n",
    "    from collections import Counter\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    y_pred = np.array([Counter(instance_forest_predictions).most_common(1)[0][0] for instance_forest_predictions in zip(*forest_predictions)])\n",
    "    #np.sum(y_test == y_pred) / len(y_test)\n",
    "    print \"Accuracy->\"+str(np.sum(y_test == y_pred)*100/ len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defined a new primitive set for strongly typed GP\n",
    "pset = gp.PrimitiveSetTyped('MAIN', itertools.repeat(float, digit_features.shape[1]), bool, 'Feature')\n",
    "\n",
    "# boolean operators\n",
    "pset.addPrimitive(operator.and_, [bool, bool], bool)\n",
    "pset.addPrimitive(operator.or_, [bool, bool], bool)\n",
    "pset.addPrimitive(operator.not_, [bool], bool)\n",
    "\n",
    "# floating point operators\n",
    "# Define a protected division function\n",
    "def protectedDiv(left, right):\n",
    "    try: return left / right\n",
    "    except (ZeroDivisionError, FloatingPointError): return 1.\n",
    "\n",
    "pset.addPrimitive(operator.add, [float, float], float)\n",
    "pset.addPrimitive(operator.sub, [float, float], float)\n",
    "pset.addPrimitive(operator.mul, [float, float], float)\n",
    "pset.addPrimitive(protectedDiv, [float, float], float)\n",
    "\n",
    "# logic operators\n",
    "# Define a new if-then-else function\n",
    "def if_then_else(in1, output1, output2):\n",
    "    if in1: return output1\n",
    "    else: return output2\n",
    "\n",
    "pset.addPrimitive(operator.lt, [float, float], bool)\n",
    "pset.addPrimitive(operator.eq, [float, float], bool)\n",
    "pset.addPrimitive(if_then_else, [bool, float, float], float)\n",
    "\n",
    "# terminals\n",
    "pset.addTerminal(False, bool)\n",
    "pset.addTerminal(True, bool)\n",
    "for val in np.arange(-10., 11.):\n",
    "    pset.addTerminal(val, float)\n",
    "\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create('Individual', gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('expr', gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
    "toolbox.register('individual', tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register('compile', gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_individual(individual):\n",
    "    global diff_global_marks\n",
    "    # Transform the tree expression into a callable function\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    \n",
    "    sample_counts = [int(func(*record)) for record in X_train]\n",
    "    sample_counts = [max(min(sample_count, 10), 0) for sample_count in sample_counts]\n",
    "    sample = []\n",
    "    for sample_index, sample_count in enumerate(sample_counts):\n",
    "        sample.extend([sample_index] * sample_count)\n",
    "    sample = np.array(sample)\n",
    "    \n",
    "    if len(sample) == 0:\n",
    "        return 1e-20, 1e-20\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=34092)\n",
    "    clf.fit(X_train[sample], y_train[sample])\n",
    "    #score = clf.score(X_test, y_test)\n",
    "    t_pred = clf.predict(X_test)\n",
    "    total_marks = np.sum((t_pred==y_test)*diff_global_marks)\n",
    "    accuracy = np.sum((t_pred==y_test))\n",
    "    \n",
    "    # Updating the diff_marks\n",
    "    bool_ = 1*(t_pred==y_test)\n",
    "    diff_global_marks = diff_global_marks-bool_\n",
    "    diff_global_marks[diff_global_marks<min_marks] = min_marks\n",
    "    \n",
    "    return total_marks, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tstd    \tmin  \tavg   \tmax  \n",
      "0  \t100   \t11686.3\t1e-20\t7058.3\t38400\n",
      "100\n",
      "1  \t100   \t5909.49\t1e-20\t3758.2\t21456\n",
      "100\n",
      "2  \t100   \t4637.75\t1e-20\t2871.73\t13412\n",
      "100\n",
      "3  \t100   \t4454.48\t1e-20\t2662.49\t13073\n",
      "100\n",
      "4  \t100   \t4681.23\t1e-20\t2990.58\t12852\n",
      "100\n",
      "5  \t100   \t4927.7 \t1e-20\t3415.08\t12804\n",
      "100\n",
      "6  \t100   \t4547.75\t1e-20\t2993.55\t12827\n",
      "100\n",
      "7  \t100   \t4780.37\t1e-20\t3421.61\t12936\n",
      "100\n",
      "8  \t100   \t4438.07\t1e-20\t3068.36\t12672\n",
      "100\n",
      "9  \t100   \t4622.99\t1e-20\t3511.12\t12706\n",
      "100\n",
      "10 \t100   \t4603.29\t1e-20\t3633.3 \t12672\n",
      "100\n",
      "11 \t100   \t4398.78\t1e-20\t3175.49\t12705\n",
      "100\n",
      "12 \t100   \t4524.34\t1e-20\t3336.46\t12739\n",
      "100\n",
      "13 \t100   \t4743.11\t1e-20\t3689.97\t12672\n",
      "100\n",
      "14 \t100   \t4801.58\t1e-20\t3684.53\t12804\n",
      "100\n",
      "15 \t100   \t4918.7 \t1e-20\t4025.07\t12738\n",
      "100\n",
      "16 \t100   \t4685.65\t1e-20\t3496.32\t12771\n",
      "100\n",
      "17 \t100   \t4831.21\t1e-20\t3540.59\t12903\n",
      "100\n",
      "18 \t100   \t4799.08\t1e-20\t3655.85\t12903\n",
      "100\n",
      "19 \t100   \t5089.86\t1e-20\t3801.03\t12903\n",
      "100\n",
      "20 \t100   \t5215.95\t1e-20\t4004.35\t12804\n",
      "100\n",
      "21 \t100   \t5074.6 \t1e-20\t3633.58\t12804\n",
      "100\n",
      "22 \t100   \t5381.54\t1e-20\t4080.68\t12804\n",
      "100\n",
      "23 \t100   \t5332.77\t1e-20\t3934.99\t12870\n",
      "100\n",
      "24 \t100   \t5408.35\t1e-20\t4276.86\t12870\n",
      "100\n",
      "25 \t100   \t5399.2 \t1e-20\t4397.22\t12804\n",
      "100\n",
      "26 \t100   \t5293.34\t1e-20\t4345.88\t12771\n",
      "100\n",
      "27 \t100   \t5337.11\t1e-20\t4520.81\t12804\n",
      "100\n",
      "28 \t100   \t5423.6 \t1e-20\t4633.18\t12738\n",
      "100\n",
      "29 \t100   \t5374.31\t1e-20\t4470.15\t12903\n",
      "100\n",
      "30 \t100   \t5059.78\t1e-20\t4021.86\t12903\n",
      "100\n",
      "31 \t100   \t5099.64\t1e-20\t3846.59\t12672\n",
      "100\n",
      "32 \t100   \t5058.69\t1e-20\t3853.9 \t12837\n",
      "100\n",
      "33 \t100   \t4784.48\t1e-20\t3360.56\t12705\n",
      "100\n",
      "34 \t100   \t4598.21\t1e-20\t3292.05\t12804\n",
      "100\n",
      "35 \t100   \t4914.9 \t1e-20\t4014.38\t12672\n",
      "100\n",
      "36 \t100   \t4827.67\t1e-20\t3878.55\t12738\n",
      "100\n",
      "37 \t100   \t4932.34\t1e-20\t4033.25\t12837\n",
      "100\n",
      "38 \t100   \t4931.83\t1e-20\t4099.55\t12837\n",
      "100\n",
      "39 \t100   \t4748.05\t1e-20\t3587.85\t12837\n",
      "100\n",
      "40 \t100   \t4869.34\t1e-20\t3722.49\t12837\n",
      "100\n",
      "41 \t100   \t4931.4 \t1e-20\t4073.37\t12837\n",
      "100\n",
      "42 \t100   \t4997.31\t1e-20\t4197.13\t12705\n",
      "100\n",
      "43 \t100   \t4989.66\t1e-20\t4514.35\t12705\n",
      "100\n",
      "44 \t100   \t5112.01\t1e-20\t4683.16\t12903\n",
      "100\n",
      "45 \t100   \t4917.64\t1e-20\t4316.64\t12738\n",
      "100\n",
      "46 \t100   \t4641.15\t1e-20\t4105.84\t12804\n",
      "100\n",
      "47 \t100   \t4552.71\t1e-20\t3979.36\t12804\n",
      "100\n",
      "48 \t100   \t4705.08\t1e-20\t4121.99\t12870\n",
      "100\n",
      "49 \t100   \t4574.68\t1e-20\t3992.79\t12870\n",
      "100\n",
      "50 \t100   \t4532.02\t1e-20\t3849.14\t12705\n",
      "100\n",
      "51 \t100   \t4595.39\t1e-20\t3921.22\t12705\n",
      "100\n",
      "52 \t100   \t4673.65\t1e-20\t4096.49\t12705\n",
      "100\n",
      "53 \t100   \t4740.95\t1e-20\t4202.23\t12903\n",
      "100\n",
      "54 \t100   \t4674.31\t1e-20\t4264.45\t12903\n",
      "100\n",
      "55 \t100   \t4454   \t1e-20\t4120.63\t12705\n",
      "100\n",
      "56 \t100   \t4709.25\t1e-20\t4313.41\t12804\n",
      "100\n",
      "57 \t100   \t4781.48\t1e-20\t4400.45\t12804\n",
      "100\n",
      "58 \t100   \t4778.6 \t1e-20\t4325.14\t12672\n",
      "100\n",
      "59 \t100   \t4799.09\t1e-20\t4336.19\t12870\n",
      "100\n",
      "Accuracy->94\n",
      "60 \t100   \t4905.95\t44   \t4571.13\t12804\n",
      "100\n",
      "61 \t100   \t4842.22\t1e-20\t4526.76\t12804\n",
      "100\n",
      "62 \t100   \t4856.34\t1e-20\t4492.76\t12738\n",
      "100\n",
      "63 \t100   \t4820.22\t1e-20\t4526.59\t12771\n",
      "100\n",
      "64 \t100   \t4878.99\t1e-20\t4410.82\t12771\n",
      "100\n",
      "65 \t100   \t4849.8 \t1e-20\t4148.17\t12804\n",
      "100\n",
      "66 \t100   \t4882.3 \t1e-20\t4139.67\t12837\n",
      "100\n",
      "67 \t100   \t4560.35\t1e-20\t3737.45\t12870\n",
      "100\n",
      "68 \t100   \t4436.52\t1e-20\t3687.13\t12870\n",
      "100\n",
      "69 \t100   \t4564.05\t1e-20\t3831.97\t12705\n",
      "100\n",
      "70 \t100   \t4574.68\t1e-20\t3576.8 \t12672\n",
      "100\n",
      "71 \t100   \t4540.07\t1e-20\t3693.93\t12705\n",
      "100\n",
      "72 \t100   \t4491.23\t1e-20\t3462.9 \t12936\n",
      "100\n",
      "73 \t100   \t4492.62\t1e-20\t3756.49\t12936\n",
      "100\n",
      "74 \t100   \t4319.84\t1e-20\t3503.19\t12936\n",
      "100\n",
      "75 \t100   \t4229.23\t1e-20\t3209.6 \t12936\n",
      "100\n",
      "76 \t100   \t4172.69\t1e-20\t3108.28\t12936\n",
      "100\n",
      "77 \t100   \t4066.68\t1e-20\t2929.95\t12672\n",
      "100\n",
      "78 \t100   \t4087.76\t1e-20\t2879.12\t12672\n",
      "100\n",
      "79 \t100   \t4156.32\t1e-20\t2807.04\t12672\n",
      "100\n",
      "80 \t100   \t3914.17\t1e-20\t2542.69\t12870\n",
      "100\n",
      "81 \t100   \t3759.1 \t1e-20\t2315.4 \t12672\n",
      "100\n",
      "82 \t100   \t4021.36\t1e-20\t2645.71\t12672\n",
      "100\n",
      "83 \t100   \t4202.02\t1e-20\t3084.65\t12672\n",
      "100\n",
      "84 \t100   \t3988.59\t1e-20\t2885.07\t12837\n",
      "100\n",
      "85 \t100   \t3641.16\t1e-20\t2606.78\t12837\n",
      "100\n",
      "86 \t100   \t3342.05\t1e-20\t2305.88\t12903\n",
      "100\n",
      "87 \t100   \t3553.17\t1e-20\t2358.41\t12672\n",
      "100\n",
      "88 \t100   \t3719.91\t1e-20\t2378.81\t12672\n",
      "100\n",
      "89 \t100   \t3808.91\t1e-20\t2518.04\t12672\n",
      "100\n",
      "90 \t100   \t4203.15\t1e-20\t2821.49\t12672\n",
      "100\n",
      "91 \t100   \t3982.32\t1e-20\t2442.05\t12672\n",
      "100\n",
      "92 \t100   \t3972.39\t1e-20\t2344.3 \t12672\n",
      "100\n",
      "93 \t100   \t3735.17\t1e-20\t2094.57\t12771\n",
      "100\n",
      "94 \t100   \t3811.62\t1e-20\t2279.87\t12672\n",
      "100\n",
      "95 \t100   \t3569.64\t1e-20\t2213.74\t12837\n",
      "100\n",
      "96 \t100   \t3579.59\t1e-20\t2242.3 \t12672\n",
      "100\n",
      "97 \t100   \t3549.97\t1e-20\t2201.84\t12672\n",
      "100\n",
      "98 \t100   \t3638.23\t1e-20\t2374.39\t12870\n",
      "100\n",
      "99 \t100   \t3785.66\t1e-20\t2575.16\t12705\n",
      "100\n",
      "100\t100   \t3599.07\t1e-20\t2327.47\t12705\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-7-75859c173a70>, line 76)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-75859c173a70>\"\u001b[1;36m, line \u001b[1;32m76\u001b[0m\n\u001b[1;33m    return population, logbook\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "toolbox.register('evaluate', evaluate_individual)\n",
    "#toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "toolbox.register('mate', gp.cxOnePoint)\n",
    "toolbox.register('expr_mut', gp.genFull, min_=0, max_=3)\n",
    "toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "population = toolbox.population(n=max_marks)\n",
    "halloffame = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "cxpb = 0.5\n",
    "mutpb = 0.5\n",
    "lambda_ = 100\n",
    "mu = max_marks\n",
    "ngen = 100\n",
    "verbose = True\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "\n",
    "# Evaluate the individuals with an invalid fitness\n",
    "invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "for ind, fit in zip(invalid_ind, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "if halloffame is not None:\n",
    "    halloffame.update(population)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "record = stats.compile(population) if stats is not None else {}\n",
    "logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "if verbose:\n",
    "    print logbook.stream\n",
    "\n",
    "# Begin the generational process\n",
    "global diff_global_marks\n",
    "all_marks = []\n",
    "all_marks.append(diff_global_marks)\n",
    "\n",
    "for gen in range(1, ngen + 1):\n",
    "    # Vary the population\n",
    "    offspring = algorithms.varOr(population, toolbox, lambda_, cxpb, mutpb)\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Update the hall of fame with the generated individuals\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "    # Select the next generation population\n",
    "    population[:] = toolbox.select(offspring, mu)\n",
    "    print len(population)\n",
    "    predict_unseen(population)\n",
    "    \n",
    "    # Just updating the all_marks array which has all the changed values\n",
    "    all_marks.append(diff_global_marks)\n",
    "    \n",
    "    # Update the statistics with the new population\n",
    "    record = stats.compile(population) if stats is not None else {}\n",
    "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print logbook.stream\n",
    "    #return population, logbook\n",
    "\n",
    "str(halloffame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5177a58dc65c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marks = pd.DataFrame(all_marks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marks.columns = [str(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marks_ = pd.DataFrame()\n",
    "for i in range(0,len(all_marks)):\n",
    "    if(i==0):\n",
    "        marks_ = pd.DataFrame(all_marks[0])\n",
    "    else:\n",
    "        if(type(all_marks[i])!=float):\n",
    "            temp_ = pd.DataFrame(all_marks[i])\n",
    "            temp_.columns = [i]\n",
    "            marks_ = pd.concat([marks_,temp_],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(marks_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_predictions = []\n",
    "\n",
    "for ind_num, individual in enumerate(population):\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    subsample = np.array([func(*record) for record in X_train])\n",
    "    \n",
    "    if X_train[subsample].shape[0] == 0:\n",
    "        continue\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=34092)\n",
    "    clf.fit(X_train[subsample], y_train[subsample])\n",
    "    predictions = clf.predict(X_test)\n",
    "    forest_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = np.array(\n",
    "    [Counter(instance_forest_predictions).most_common(1)[0][0] for instance_forest_predictions in zip(*forest_predictions)])\n",
    "#np.sum(y_test == y_pred) / len(y_test)\n",
    "np.sum(y_test == y_pred)*100/ len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func = toolbox.compile(expr=halloffame[0])\n",
    "subsample = np.array([func(*record) for record in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print halloffame[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-db75ffb14134>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-db75ffb14134>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    type(Integer((0.5*100))\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "(0.5*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chk = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
