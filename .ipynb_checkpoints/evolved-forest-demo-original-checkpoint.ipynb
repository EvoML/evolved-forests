{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base DecisionTreeClassifier accuracy: 0.869179600887\n",
      "Base RandomForestClassifier accuracy: 0.946784922395\n",
      "Base GradientBoostingClassifier accuracy: 0.953436807095\n",
      "\n",
      "gen\tnevals\tstd     \tmin  \tavg     \tmax     \n",
      "0  \t100   \t0.379036\t1e-20\t0.394612\t0.875831\n",
      "1  \t85    \t0.337387\t1e-20\t0.584945\t0.878049\n",
      "2  \t76    \t0.300443\t1e-20\t0.709135\t0.873614\n",
      "3  \t73    \t0.311377\t1e-20\t0.707761\t0.873614\n",
      "4  \t75    \t0.251842\t1e-20\t0.774656\t0.875831\n",
      "5  \t73    \t0.268957\t1e-20\t0.754745\t0.880266\n",
      "6  \t71    \t0.21039 \t1e-20\t0.80051 \t0.882483\n",
      "7  \t78    \t0.209782\t1e-20\t0.811175\t0.882483\n",
      "8  \t77    \t0.125856\t1e-20\t0.852106\t0.891353\n",
      "9  \t71    \t0.132058\t1e-20\t0.843259\t0.891353\n",
      "10 \t76    \t0.0994663\t1e-20\t0.855277\t0.891353"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "digits = load_digits()\n",
    "digit_features, digit_labels = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(digit_features, digit_labels, stratify=digit_labels,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "# defined a new primitive set for strongly typed GP\n",
    "pset = gp.PrimitiveSetTyped('MAIN', itertools.repeat(float, digit_features.shape[1]), bool, 'Feature')\n",
    "\n",
    "# boolean operators\n",
    "pset.addPrimitive(operator.and_, [bool, bool], bool)\n",
    "pset.addPrimitive(operator.or_, [bool, bool], bool)\n",
    "pset.addPrimitive(operator.not_, [bool], bool)\n",
    "\n",
    "# floating point operators\n",
    "# Define a protected division function\n",
    "def protectedDiv(left, right):\n",
    "    try: return left / right\n",
    "    except (ZeroDivisionError, FloatingPointError): return 1.\n",
    "\n",
    "pset.addPrimitive(operator.add, [float, float], float)\n",
    "pset.addPrimitive(operator.sub, [float, float], float)\n",
    "pset.addPrimitive(operator.mul, [float, float], float)\n",
    "pset.addPrimitive(protectedDiv, [float, float], float)\n",
    "\n",
    "# logic operators\n",
    "# Define a new if-then-else function\n",
    "def if_then_else(in1, output1, output2):\n",
    "    if in1: return output1\n",
    "    else: return output2\n",
    "\n",
    "pset.addPrimitive(operator.lt, [float, float], bool)\n",
    "pset.addPrimitive(operator.eq, [float, float], bool)\n",
    "pset.addPrimitive(if_then_else, [bool, float, float], float)\n",
    "\n",
    "# terminals\n",
    "pset.addTerminal(False, bool)\n",
    "pset.addTerminal(True, bool)\n",
    "for val in np.arange(-10., 11.):\n",
    "    pset.addTerminal(val, float)\n",
    "\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "creator.create('Individual', gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('expr', gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
    "toolbox.register('individual', tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register('compile', gp.compile, pset=pset)\n",
    "\n",
    "def evaluate_individual(individual):\n",
    "    # Transform the tree expression into a callable function\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    subsample = np.array([func(*record) for record in X_train])\n",
    "    \n",
    "    if X_train[subsample].shape[0] == 0:\n",
    "        return 1e-20,\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=34092)\n",
    "    clf.fit(X_train[subsample], y_train[subsample])\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    return score,\n",
    "    \n",
    "toolbox.register('evaluate', evaluate_individual)\n",
    "toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "toolbox.register('mate', gp.cxOnePoint)\n",
    "toolbox.register('expr_mut', gp.genFull, min_=0, max_=3)\n",
    "toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "population = toolbox.population(n=100)\n",
    "halloffame = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Base DecisionTreeClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf = RandomForestClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Base RandomForestClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=34092)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Base GradientBoostingClassifier accuracy: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "print('')\n",
    "\n",
    "cxpb = 0.5\n",
    "mutpb = 0.5\n",
    "ngen = 50\n",
    "verbose = True\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "# Evaluate the individuals with an invalid fitness\n",
    "invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "for ind, fit in zip(invalid_ind, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "if halloffame is not None:\n",
    "    halloffame.update(population)\n",
    "\n",
    "record = stats.compile(population) if stats else {}\n",
    "logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "if verbose:\n",
    "    print(logbook.stream)\n",
    "\n",
    "# Begin the generational process\n",
    "for gen in range(1, ngen + 1):\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "\n",
    "    # Vary the pool of individuals\n",
    "    offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Update the hall of fame with the generated individuals\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(offspring)\n",
    "\n",
    "    # Replace the current population by the offspring\n",
    "    population[:] = offspring\n",
    "\n",
    "    # Append the current generation statistics to the logbook\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "str(halloffame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_predictions = []\n",
    "\n",
    "for ind_num, individual in enumerate(pop):\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    subsample = np.array([func(*record) for record in X_train])\n",
    "    \n",
    "    if X_train[subsample].shape[0] == 0:\n",
    "        continue\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=34092)\n",
    "    clf.fit(X_train[subsample], y_train[subsample])\n",
    "    predictions = clf.predict(X_test)\n",
    "    forest_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = np.array(\n",
    "    [Counter(instance_forest_predictions).most_common(1)[0][0] for instance_forest_predictions in zip(*forest_predictions)])\n",
    "np.sum(y_test == y_pred) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
